{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport glob\nimport pandas as pd\npd.set_option('display.max_colwidth', None)  \nimport numpy as np\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport matplotlib\nmatplotlib.rcParams['animation.html'] = 'jshtml'\nimport seaborn as sns\nimport datetime\nimport csv\n\nimport pydicom\nimport torch\n\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom torch.utils.data import DataLoader\n\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:05.223642Z","iopub.execute_input":"2021-11-21T10:37:05.224285Z","iopub.status.idle":"2021-11-21T10:37:07.679195Z","shell.execute_reply.started":"2021-11-21T10:37:05.224152Z","shell.execute_reply":"2021-11-21T10:37:07.678313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"root_dir = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/'\n\ndf = pd.read_csv(root_dir+'train_labels.csv')\nbad_image = [109, 123, 709]\ndf = df[~df['BraTS21ID'].isin(bad_image)].reset_index(drop=True)\nprint(len(df['MGMT_value']==1))\nprint(len(df['MGMT_value']==0))","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.680433Z","iopub.execute_input":"2021-11-21T10:37:07.680877Z","iopub.status.idle":"2021-11-21T10:37:07.727502Z","shell.execute_reply.started":"2021-11-21T10:37:07.680848Z","shell.execute_reply":"2021-11-21T10:37:07.726697Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load patiennt path\n# zfill example, id=5, output = 00005\npatient_path=[]\nfor i in range(df.shape[0]):\n    id = df.iloc[i][\"BraTS21ID\"]\n    patient_path.append(os.path.join(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/train/\",str(id).zfill(5)))","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.729043Z","iopub.execute_input":"2021-11-21T10:37:07.729448Z","iopub.status.idle":"2021-11-21T10:37:07.800909Z","shell.execute_reply.started":"2021-11-21T10:37:07.729416Z","shell.execute_reply":"2021-11-21T10:37:07.800122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndirectory ={'FLAIR':[],'T1w':[],'T1wCE':[],'T2w':[]}\nfor path in patient_path:\n    directory['FLAIR'].append(os.path.join(path, 'FLAIR'))\n    directory['T1w'].append(os.path.join(path, 'T1w'))\n    directory['T1wCE'].append(os.path.join(path, 'T1wCE'))\n    directory['T2w'].append(os.path.join(path, 'T2w'))\n    \ndirectory = pd.DataFrame(directory)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.802136Z","iopub.execute_input":"2021-11-21T10:37:07.802602Z","iopub.status.idle":"2021-11-21T10:37:07.817069Z","shell.execute_reply.started":"2021-11-21T10:37:07.802555Z","shell.execute_reply":"2021-11-21T10:37:07.816015Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_stacked_images(images_slices):\n    images = []\n    for image in images_slices:\n        if(np.max(image)!=0):\n            images.append(image) \n    stacked_images = np.stack(images,0)\n    return stacked_images\n    \ndef load_image(file):\n    data = pydicom.read_file(file)\n    data = data.pixel_array\n    return data","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.818322Z","iopub.execute_input":"2021-11-21T10:37:07.81878Z","iopub.status.idle":"2021-11-21T10:37:07.831127Z","shell.execute_reply.started":"2021-11-21T10:37:07.818748Z","shell.execute_reply":"2021-11-21T10:37:07.830181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn.functional as F\nimport time\nMAX_PIXEL_VAL = 255\nMEAN = 58.09\nSTD = 49.73\n\n\ndef preprocess_data(path, transform=None):\n#     start = time.time()\n    images_path = sorted(glob.glob(os.path.join(path,\"*\")),key=lambda x: int(x[:-4].split(\"-\")[-1]))\n    images_slices = [load_image(image_path) for image_path in images_path]\n    series = get_stacked_images(images_slices).astype(np.float32)\n#     print('time:',time.time()-start)\n    series = torch.tensor(np.stack((series,)*3, axis=1))\n    resized = F.interpolate(series,(256))\n    resized = resized.permute(0,1,3,2)\n    resized = F.interpolate(resized,(256))\n    series = resized.permute(0,1,3,2)\n#     print(series.shape)\n\n    if transform is not None:\n        for i, slice in enumerate(series.split(1)):\n            series[i] = transform(slice.squeeze())\n\n    series = (series - series.min()) / (series.max() - series.min()) * MAX_PIXEL_VAL\n    series = (series - MEAN) / STD\n#     print('time:',time.time()-start)\n    return series","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.832385Z","iopub.execute_input":"2021-11-21T10:37:07.83273Z","iopub.status.idle":"2021-11-21T10:37:07.845521Z","shell.execute_reply.started":"2021-11-21T10:37:07.832701Z","shell.execute_reply":"2021-11-21T10:37:07.844511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class customDataset(Dataset):\n    def __init__(self, dataset_dir, labels, transform=None, device=None):\n        self.paths = dataset_dir\n        self.labels = labels\n        self.transform = transform\n        self.device = device\n        if self.device is None:\n            self.device = 'cuda' if torch.cuda.is_available() else 'cpu'\n\n    def __len__(self):\n        return len(self.paths)\n\n    def __getitem__(self, idx):\n\n        path = self.paths[idx]\n        series = preprocess_data(path, self.transform)\n        labels = torch.tensor(self.labels[idx].astype(np.float32))\n        return (series, labels)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.846747Z","iopub.execute_input":"2021-11-21T10:37:07.847255Z","iopub.status.idle":"2021-11-21T10:37:07.862295Z","shell.execute_reply.started":"2021-11-21T10:37:07.847223Z","shell.execute_reply":"2021-11-21T10:37:07.861308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def split_dataset(dataset_dir,labels):\n    \n    train_size = int(len(dataset_dir)*0.7)\n    valid_size = len(dataset_dir)-train_size\n    train_dataset = dataset_dir[0:train_size]\n    train_labels = labels[0:train_size]\n    valid_dataset = dataset_dir[-valid_size:].reset_index(drop=True)\n    valid_labels = labels[-valid_size:].reset_index(drop=True)\n    \n    return train_dataset,train_labels,valid_dataset,valid_labels\n\ndef make_dataset(directory,mri_type, dataset_type, device=None):\n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    dataset = directory[mri_type]\n    labels = df['MGMT_value']\n    \n    train_dataset,train_labels,valid_dataset,valid_labels = split_dataset(dataset,labels)\n    \n    if dataset_type == 'train':\n        dataset_dir = train_dataset\n        labels = train_labels\n        transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.RandomHorizontalFlip(),\n            transforms.RandomAffine(25, translate=(0.1, 0.1)),\n            transforms.ToTensor()\n        ])\n    elif dataset_type == 'valid':\n        dataset_dir = valid_dataset\n        labels = valid_labels\n        transform = transforms.Compose([\n            transforms.ToPILImage(),\n            transforms.ToTensor()\n        ])\n    else:\n        raise ValueError('Dataset needs to be train or valid.')\n\n    dataset = customDataset(dataset_dir, labels, transform=transform, device=device)\n\n    return dataset\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.865063Z","iopub.execute_input":"2021-11-21T10:37:07.865423Z","iopub.status.idle":"2021-11-21T10:37:07.877125Z","shell.execute_reply.started":"2021-11-21T10:37:07.86539Z","shell.execute_reply":"2021-11-21T10:37:07.875961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_data_loader(directory,mri_type,dataset_type,device=None,shuffle=False):\n    \n    if device is None:\n        device = 'cuda' if torch.cuda.is_available() else 'cpu'\n    dataset = make_dataset(directory,mri_type,dataset_type,device)\n    data_loader = DataLoader(dataset, batch_size=1, shuffle=shuffle)\n\n    return data_loader","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.879368Z","iopub.execute_input":"2021-11-21T10:37:07.879726Z","iopub.status.idle":"2021-11-21T10:37:07.894007Z","shell.execute_reply.started":"2021-11-21T10:37:07.879693Z","shell.execute_reply":"2021-11-21T10:37:07.89301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Model","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torchvision import models\n\nclass MRNet(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.alexnet = torch.load('../input/alexnet/alexnet.pth').features\n        self.fc = nn.Linear(256, 1)\n\n        self.avg_pool = nn.AvgPool2d(kernel_size=7, stride=None, padding=0)\n        self.dropout = nn.Dropout(p=0.5)\n\n    @property\n    def features(self):\n        return self.alexnet\n\n    @property\n    def classifier(self):\n        return self.fc\n\n    def forward(self, batch):\n        batch_out = torch.tensor([]).to(batch.device)\n\n        for series in batch:\n            out = torch.tensor([]).to(batch.device)\n            for image in series:\n                out = torch.cat((out, self.features(image.unsqueeze(0))), 0)\n\n            out = self.avg_pool(out).squeeze()\n            out = out.max(dim=0, keepdim=True)[0].squeeze()\n\n            out = self.classifier(self.dropout(out))\n\n            batch_out = torch.cat((batch_out, out), 0)\n\n        return batch_out","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.895431Z","iopub.execute_input":"2021-11-21T10:37:07.89587Z","iopub.status.idle":"2021-11-21T10:37:07.908979Z","shell.execute_reply.started":"2021-11-21T10:37:07.895825Z","shell.execute_reply":"2021-11-21T10:37:07.907781Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_losses_csv(out_dir, mri_type):\n    loss_path = f'{out_dir}/loss_{mri_type}.csv'\n\n    with open(f'{loss_path}', mode='w') as loss_csv:\n        fields = ['train_loss','valid_loss']\n        writer = csv.DictWriter(loss_csv, fieldnames=fields)\n        writer.writeheader()\n\n    return loss_path\n\ndef create_output_dir(exp, mri_type):\n    out_dir = f'./{exp}'\n    if not os.path.exists(out_dir):\n        os.makedirs(out_dir)\n\n    loss_path = create_losses_csv(out_dir,mri_type)\n\n    return out_dir, loss_path","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.91016Z","iopub.execute_input":"2021-11-21T10:37:07.910604Z","iopub.status.idle":"2021-11-21T10:37:07.926173Z","shell.execute_reply.started":"2021-11-21T10:37:07.910556Z","shell.execute_reply":"2021-11-21T10:37:07.925332Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data_dir = \"../input/mrnet-v1/MRNet-v1.0\"\n# mri_type = 'T1w'\ndevice = None\nlr = 0.00001\nweight_decay = 0.01","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.927331Z","iopub.execute_input":"2021-11-21T10:37:07.927814Z","iopub.status.idle":"2021-11-21T10:37:07.93811Z","shell.execute_reply.started":"2021-11-21T10:37:07.927772Z","shell.execute_reply":"2021-11-21T10:37:07.936998Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def calculate_weights(mri_type, device):\n\n    labels_df = df['MGMT_value']\n\n    neg_count, pos_count = labels_df.value_counts().sort_index()\n    weight = torch.tensor([neg_count / pos_count])\n    weight = weight.to(device)\n    return weight\n\ndef make_adam_optimizer(model, lr, weight_decay):\n    return optim.Adam(model.parameters(), lr, weight_decay=weight_decay)\n\ndef make_lr_scheduler(optimizer,\n                      mode='min',\n                      factor=0.3,\n                      patience=1,\n                      verbose=False):\n    return optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n                                                mode=mode,\n                                                factor=factor,\n                                                patience=patience,\n                                                verbose=verbose)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.939392Z","iopub.execute_input":"2021-11-21T10:37:07.939751Z","iopub.status.idle":"2021-11-21T10:37:07.951982Z","shell.execute_reply.started":"2021-11-21T10:37:07.939721Z","shell.execute_reply":"2021-11-21T10:37:07.950872Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# In order to train ther other models, change mri_type to t1w,flair,or t2w\nmri_type = 'T1wCE'\nexp = f'{datetime.datetime.now():%Y-%m-%d_%H-%M}'\nout_dir, loss_path = create_output_dir(exp, mri_type)\ndevice=None\nif device is None:\n    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n        \ntrain_loader = make_data_loader(directory,mri_type,'train',device=device,shuffle=True)\nvalid_loader = make_data_loader(directory,mri_type, 'valid', device)\n\nprint(f'Creating models...')\n\n# Create a model for each diagnosis\n\nmodel = MRNet().to(device)\n\nweight = calculate_weights(mri_type, device)\ncriterion = nn.BCEWithLogitsLoss(pos_weight=weight)\n\noptimizer = make_adam_optimizer(model, lr, weight_decay)\n\nlr_scheduler = make_lr_scheduler(optimizer)\n\nmin_valid_loss = np.inf\n\nprint(f'Training a model using {mri_type} series...')\nprint(f'Checkpoints and losses will be save to {out_dir}')","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:07.954968Z","iopub.execute_input":"2021-11-21T10:37:07.955444Z","iopub.status.idle":"2021-11-21T10:37:11.747826Z","shell.execute_reply.started":"2021-11-21T10:37:07.9554Z","shell.execute_reply":"2021-11-21T10:37:11.74674Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import metrics\n# LAbel may be label[0]\ndef batch_forward_backprop(model, inputs, label, criterion, optimizer):\n\n\n    model.train()\n    optimizer.zero_grad()\n\n    out = model(inputs)\n    loss = criterion(out, label)\n    loss.backward()\n    optimizer.step()\n\n    return loss.item()\n\n\ndef batch_forward(model, inputs, label, criterion):\n    \n    model.eval()\n    out = model(inputs)\n    loss = criterion(out, label)\n    \n    return out.item(), loss.item()\n\n\ndef update_lr_scheduler(lr_scheduler, batch_valid_loss):\n    lr_scheduler.step(batch_valid_loss)\n        \ndef calculate_auc(all_labels, all_preds):\n\n    auc = metrics.roc_auc_score(all_labels, all_preds)\n\n    return auc\n\n\ndef print_stats(batch_train_loss, batch_valid_loss,\n                valid_label, valid_pred):\n    auc = calculate_auc(valid_label, valid_pred)\n\n    print(f'Train losses: {batch_train_loss:.3f},',\n          f'\\nValid losses: {batch_valid_loss:.3f},',\n          f'\\nValid AUCs: {auc:.3f},')\n\n\ndef save_losses(train_loss , valid_loss, loss_path):\n    with open(f'{loss_path}', mode='a') as loss_csv:\n        writer = csv.writer(loss_csv)\n        writer.writerow(np.append(train_loss, valid_loss))\n\n\ndef save_checkpoint(epoch, mri_type, model, optimizer, out_dir):\n    print('Min valid loss, saving the checkpoint...')\n\n    checkpoint = {\n        'epoch': epoch,\n        'mri_type': mri_type,\n        'state_dict': model.state_dict(),\n        'optimizer': optimizer.state_dict()\n    }\n\n    chkpt = f'cnn_{mri_type}_{epoch:2d}.pt'\n    torch.save(checkpoint,chkpt)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:11.74923Z","iopub.execute_input":"2021-11-21T10:37:11.749524Z","iopub.status.idle":"2021-11-21T10:37:11.931108Z","shell.execute_reply.started":"2021-11-21T10:37:11.749496Z","shell.execute_reply":"2021-11-21T10:37:11.92987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train Model","metadata":{"_kg_hide-input":true}},{"cell_type":"code","source":"epochs=5\nfor epoch, _ in enumerate(range(epochs), 1):\n        print(f'=== Epoch {epoch}/{epochs} ===')\n\n        batch_train_loss = 0.0\n        batch_valid_loss = 0.0\n\n        for inputs, labels in tqdm(train_loader,total=len(train_loader)):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            batch_loss = batch_forward_backprop(model, inputs, labels,\n                                                criterion, optimizer)\n            batch_train_loss += batch_loss\n        \n        valid_preds = []\n        valid_labels = []\n\n        for inputs, labels in tqdm(valid_loader,total=len(valid_loader)):\n            inputs, labels = inputs.to(device), labels.to(device)\n\n            batch_preds, batch_loss = batch_forward(model, inputs, labels, criterion)\n            batch_valid_loss += batch_loss\n\n            valid_labels.append(labels.detach().cpu().numpy())\n            valid_preds.append(batch_preds)\n\n        batch_train_loss /= len(train_loader)\n        batch_valid_loss /= len(valid_loader)\n\n        print_stats(batch_train_loss, batch_valid_loss,\n                    valid_labels, valid_preds)\n        save_losses(batch_train_loss, batch_valid_loss, loss_path)\n\n        update_lr_scheduler(lr_scheduler, batch_valid_loss)\n\n        if batch_valid_loss < min_valid_loss:\n            save_checkpoint(epoch, mri_type, model,optimizer, out_dir)\n\n            min_valid_loss = batch_valid_loss","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-21T10:37:11.932824Z","iopub.execute_input":"2021-11-21T10:37:11.933273Z","iopub.status.idle":"2021-11-21T10:37:11.939021Z","shell.execute_reply.started":"2021-11-21T10:37:11.933226Z","shell.execute_reply":"2021-11-21T10:37:11.937763Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nmodels = []\nfor mri_type in mri_types:\n#     checkpoint_pattern = glob.glob(f'./cnn_{mri_type}*.pt')\n#     checkpoint_path = sorted(checkpoint_pattern)[-1]\n    checkpoint_path = f'../input/models/cnn_{mri_type}.pt'\n    checkpoint = torch.load(checkpoint_path, map_location=device)\n\n    model = MRNet().to(device)\n    model.load_state_dict(checkpoint['state_dict'])\n    models.append(model)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-21T10:37:11.941804Z","iopub.execute_input":"2021-11-21T10:37:11.942394Z","iopub.status.idle":"2021-11-21T10:37:11.953702Z","shell.execute_reply.started":"2021-11-21T10:37:11.942327Z","shell.execute_reply":"2021-11-21T10:37:11.952827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Creating data loaders...')\n\nflair_loader = make_data_loader('FLAIR', 'train')\nt1w_loader = make_data_loader('T1w', 'train')\nt1wce_loader = make_data_loader('T1wCE', 'train')\nt2w_loader = make_data_loader('T2w', 'train')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-21T10:37:11.954751Z","iopub.execute_input":"2021-11-21T10:37:11.955097Z","iopub.status.idle":"2021-11-21T10:37:11.964314Z","shell.execute_reply.started":"2021-11-21T10:37:11.955066Z","shell.execute_reply":"2021-11-21T10:37:11.963468Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.linear_model import LogisticRegressionCV\nprint(f'Collecting predictions on train dataset from the models...')\n\nys= []\nXs = []  # Abnormal, ACL, Meniscus\nwith tqdm(total=len(flair_loader)) as pbar:\n    for (flair_inputs, label), (t1w_inputs, _), (t1wce_inputs, _), (t2w_inputs,_) in \\\n            zip(flair_loader, t1w_loader, t1wce_loader,t2w_loader):\n\n        flair_inputs, t1w_inputs, t1wce_inputs, t2w_inputs = \\\n            flair_inputs.to(device),t1w_inputs.to(device), t1wce_inputs.to(device), t2w_inputs.to(device)\n\n        ys.append(label.cpu().tolist())\n\n        flair_prediction = models[0](flair_inputs).detach().cpu().item()\n        t1w_prediction = models[1](t1w_inputs).detach().cpu().item()\n        t1wce_prediction = models[2](t1wce_inputs).detach().cpu().item()\n        t2w_prediction = models[3](t2w_inputs).detach().cpu().item()\n        predictions = [flair_prediction,t1w_prediction,t1wce_prediction,t2w_prediction]\n        Xs.append(predictions)\n\n        pbar.update(1)\n\n\n","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-21T10:37:11.96556Z","iopub.execute_input":"2021-11-21T10:37:11.966001Z","iopub.status.idle":"2021-11-21T10:37:11.97879Z","shell.execute_reply.started":"2021-11-21T10:37:11.965957Z","shell.execute_reply":"2021-11-21T10:37:11.977814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'Training logistic regression models for each condition...')\n\n\nclf = LogisticRegressionCV(cv=5, random_state=0).fit(Xs, y)\n\n\nprint(f'Cross validation score: {clf.score(Xs, ys):.3f}')\nclf_path = './lr.pkl'\njoblib.dump(clf, clf_path)\n\nprint(f'Logistic regression models saved to output')","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2021-11-21T10:37:11.980037Z","iopub.execute_input":"2021-11-21T10:37:11.980489Z","iopub.status.idle":"2021-11-21T10:37:11.989506Z","shell.execute_reply.started":"2021-11-21T10:37:11.980442Z","shell.execute_reply":"2021-11-21T10:37:11.988741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Submissions","metadata":{}},{"cell_type":"code","source":"root_dir = '../input/rsna-miccai-brain-tumor-radiogenomic-classification/'\nsubmission = pd.read_csv(root_dir+'sample_submission.csv')\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:11.990742Z","iopub.execute_input":"2021-11-21T10:37:11.991017Z","iopub.status.idle":"2021-11-21T10:37:12.008853Z","shell.execute_reply.started":"2021-11-21T10:37:11.990991Z","shell.execute_reply":"2021-11-21T10:37:12.008024Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load patiennt path\n# zfill example, id=5, output = 00005\ntest_patient_path=[]\nfor i in range(submission.shape[0]):\n    id = submission.iloc[i][\"BraTS21ID\"]\n#     print(str(int(id)))\n    test_patient_path.append(os.path.join(\"../input/rsna-miccai-brain-tumor-radiogenomic-classification/test/\",str(int(id)).zfill(5)))","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:12.010035Z","iopub.execute_input":"2021-11-21T10:37:12.010479Z","iopub.status.idle":"2021-11-21T10:37:12.032121Z","shell.execute_reply.started":"2021-11-21T10:37:12.010444Z","shell.execute_reply":"2021-11-21T10:37:12.031116Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_directory ={'FLAIR':[],'T1w':[],'T1wCE':[],'T2w':[]}\nfor path in test_patient_path:\n    test_directory['FLAIR'].append(os.path.join(path, 'FLAIR'))\n    test_directory['T1w'].append(os.path.join(path, 'T1w'))\n    test_directory['T1wCE'].append(os.path.join(path, 'T1wCE'))\n    test_directory['T2w'].append(os.path.join(path, 'T2w'))\n    \ntest_directory = pd.DataFrame(test_directory)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:12.035058Z","iopub.execute_input":"2021-11-21T10:37:12.035669Z","iopub.status.idle":"2021-11-21T10:37:12.048858Z","shell.execute_reply.started":"2021-11-21T10:37:12.035605Z","shell.execute_reply":"2021-11-21T10:37:12.048067Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"output_file = 'submission.csv'\nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nmrnets=[]\nfor mri_type in mri_types:\n    model=MRNet().to(device)\n    mrnet_path = f'../input/models/cnn_{mri_type}.pt'\n    checkpoint = torch.load(mrnet_path,map_location=device)\n    model.load_state_dict(checkpoint['state_dict'])\n    mrnets.append(model)\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:12.050045Z","iopub.execute_input":"2021-11-21T10:37:12.050323Z","iopub.status.idle":"2021-11-21T10:37:13.810358Z","shell.execute_reply.started":"2021-11-21T10:37:12.050296Z","shell.execute_reply":"2021-11-21T10:37:13.809349Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import joblib\nlr_model = joblib.load('../input/lr-models/lr.pkl')\n\n\ntransform = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor()\n    ])\n\nprint(f'Generating predictions ')\nprint(f'Predictions will be saved as {output_file}')\n\n\nlr_preds=[]\nfor i in range(len(test_directory)):\n    \n    data=[]\n    for mri_type in mri_types:\n        \n        path = test_directory[mri_type].iloc[i]\n        preprocessed = preprocess_data(path, transform)\n        data.append(preprocessed.unsqueeze(0).to(device))\n    \n    FLAIR_pred = mrnets[0](data[0]).detach().cpu().item()\n    T1w_pred = mrnets[1](data[1]).detach().cpu().item()\n    T1wCE_pred = mrnets[2](data[2]).detach().cpu().item()\n    T2w_pred = mrnets[3](data[3]).detach().cpu().item()\n    \n    X = [[FLAIR_pred, T1w_pred, T1wCE_pred, T2w_pred]]\n    \n    lr_preds.append(np.float64(lr_model.predict_proba(X)[:,1]))\n","metadata":{"execution":{"iopub.status.busy":"2021-11-21T10:37:13.811888Z","iopub.execute_input":"2021-11-21T10:37:13.812311Z","iopub.status.idle":"2021-11-21T11:03:03.000744Z","shell.execute_reply.started":"2021-11-21T10:37:13.812267Z","shell.execute_reply":"2021-11-21T11:03:02.998687Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['MGMT_value']=lr_preds\nsubmission.to_csv(output_file,index=False)","metadata":{"execution":{"iopub.status.busy":"2021-11-21T11:03:03.001732Z","iopub.status.idle":"2021-11-21T11:03:03.002382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}